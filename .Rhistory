## Marital Status - Creating 2 categories of Single and together
data.clean$Marital_Status[data.clean$Marital_Status == "Absurd"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "Alone"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "YOLO"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "Single"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "Together"] <- 1
data.clean$Marital_Status[data.clean$Marital_Status == "Married"] <- 1
data.clean$Marital_Status[data.clean$Marital_Status == "Divorced"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "Widow"] <- 0
data.clean$Marital_Status <- as.numeric(data.clean$Marital_Status)
## Dt_customer
data.clean$Dt_Customer <- dmy(data.clean$Dt_Customer)
data.clean$Dt_Customer <- year(data.clean$Dt_Customer)
data.clean$Dt_Customer <- as.factor(data.clean$Dt_Customer)
data.clean$Dt_Customer <- fct_collapse(data.clean$Dt_Customer,
"3" = "2014",
"1" = "2012",
"2" = "2013")
data.clean$Dt_Customer <- as.numeric(levels(data.clean$Dt_Customer))[data.clean$Dt_Customer]
# Adding Age variable
data.clean$Age <- (2015 - data.clean$Year_Birth)
# filter numerical columns
numerical.data = data.clean[, c(3:21)]#:ncol(data.ori))]
str(numerical.data)
par(mfrow=c(1,1))
corr_simple <- function(data=numerical.data,sig=0.5){
#convert data to numeric in order to run correlations
#convert to factor first to keep the integrity of the data - each value will become a number rather than turn into NA
df_cor <- data %>% mutate_if(is.character, as.factor)
df_cor <- df_cor %>% mutate_if(is.factor, as.numeric)
#run a correlation and drop the insignificant ones
corr <- cor(df_cor)
#prepare to drop duplicates and correlations of 1
corr[lower.tri(corr,diag=TRUE)] <- NA
#drop perfect correlations
corr[corr == 1] <- NA
#turn into a 3-column table
corr <- as.data.frame(as.table(corr))
#remove the NA values from above
corr <- na.omit(corr)
#select significant values
corr <- subset(corr, abs(Freq) > sig)
#sort by highest correlation
corr <- corr[order(-abs(corr$Freq)),]
#print table
print(corr)
#turn corr back into matrix in order to plot with corrplot
mtx_corr <- reshape2::acast(corr, Var1~Var2, value.var="Freq")
#plot correlations visually
corrplot(mtx_corr, is.corr=T, tl.col="black", method = 'number', na.label=" ", number.cex=0.8 ,tl.cex=0.8)
}
corr_simple()
par(mfrow=c(4,5))
hist(data.clean$Education, main="Education", xlab=" ")
hist(data.clean$Marital_Status, main="Marital_Status", xlab=" ", ylab = " ")
hist(data.clean$Income, main="Income", xlab=" ", ylab = " ")
hist(data.clean$Kidhome, main="Kidhome", xlab=" ", ylab = " ")
hist(data.clean$Teenhome, main="Teenhome", xlab=" ", ylab = " ")
hist(data.clean$Dt_Customer, main="Dt_Customer", xlab=" ")
hist(data.clean$Recency, main="Recency", xlab=" ", ylab = " ")
hist(data.clean$MntWines, main="MntWines", xlab=" ", ylab = " ")
hist(data.clean$MntFruits, main="MntFruits", xlab=" ", ylab = " ")
hist(data.clean$MntMeatProducts, main="MntMeat", xlab=" ", ylab = " ")
hist(data.clean$MntFishProducts, main="MntFish", xlab=" ")
hist(data.clean$MntSweetProducts, main="MntSweet", xlab=" ", ylab = " ")
hist(data.clean$MntGoldProds, main="MntGold", xlab=" ", ylab = " ")
hist(data.clean$NumDealsPurchases, main="NumDeals", xlab=" ", ylab = " ")
hist(data.clean$NumWebPurchases, main="NumWeb", xlab=" ", ylab = " ")
hist(data.clean$NumCatalogPurchases, main="NumCatalog", xlab=" ")
hist(data.clean$NumStorePurchases, main="NumStore", xlab=" ", ylab = " ")
hist(data.clean$NumWebVisitsMonth, main="NumWebVisits", xlab=" ", ylab = " ")
hist(data.clean$Age, main="Age", xlab=" ", ylab = " ")
par(mfrow=c(1,1))
features.order = c("Education", "Marital_Status", "Kidhome", "Teenhome", "Age",
"Dt_Customer", "Income", "Recency", "MntWines", "MntFruits",
"MntMeatProducts", "MntFishProducts", "MntSweetProducts",
"MntGoldProds", "NumDealsPurchases", "NumWebPurchases",
"NumCatalogPurchases", "NumStorePurchases", "NumWebVisitsMonth")
# get the polychroic correlation
fa.cor = POLYCHORIC_R(numerical.data)
# look at eigenvector of the correlation to see how many factors we use
fa.eigen = eigen(fa.cor)
fa.eigen$values
# in decreasing values
# higher = more important
# rule of thumb to see the number of variables we should use? Do the sum
sum(fa.eigen$values)
# to select number of factors
cumsum(fa.eigen$values) / ncol(numerical.data) # Which is 19 here
# seeing this, using the first 4, we can explain 79% of the data
# draw screen plot for better visualisation
# use the scree plot
plot(fa.eigen$values, type = "b", ylab = "Eigenvalues", xlab = "Factor") # we choose 4 factors
# factor analysis with rotation
fa.res.rot = factanal(x = numerical.data, factors = 4, rotation = "promax", scores = "Bartlett")
head(fa.res.rot$scores)
# show the result
summary(lm(Factor2 ~ Factor1, data = as.data.frame(fa.res.rot$scores)))
fa.res.rot.loading  = data.frame(fa.res.rot$loadings[1:19,1:4])
fa.res.rot.loading$features = rownames(fa.res.rot.loading)
colnames(fa.res.rot.loading) = c('F1','F2','F3','F4','features')
# create a new data frame with the selected principal components
# prepare data for heat map
fa.res.df = melt(fa.res.rot.loading)
fa.res.df$features = factor(fa.res.df$features, levels = c("Education", "Marital_Status", "Kidhome", "Teenhome", "Age",
"Dt_Customer", "Income", "Recency", "MntWines", "MntFruits",
"MntMeatProducts", "MntFishProducts", "MntSweetProducts",
"MntGoldProds", "NumDealsPurchases", "NumWebPurchases",
"NumCatalogPurchases", "NumStorePurchases", "NumWebVisitsMonth"))
# Apply PCA to data
pc.res = prcomp(numerical.data, scale = TRUE)
pc.res
# we pick 9 components to explain 80% of variance
cumsum(pc.res$sdev^2/sum(pc.res$sdev^2))
pc.loading = data.frame(pc.res$rotation[1:19,1:9])
pc.loading
# prepare data for heat map
pc.loading$features = rownames(pc.loading)
pr.loading.df = melt(pc.loading)
pr.loading.df$features = factor(pr.loading.df$features, levels = c("Education", "Marital_Status", "Kidhome", "Teenhome", "Age",
"Dt_Customer", "Income", "Recency", "MntWines", "MntFruits",
"MntMeatProducts", "MntFishProducts", "MntSweetProducts",
"MntGoldProds", "NumDealsPurchases", "NumWebPurchases",
"NumCatalogPurchases", "NumStorePurchases", "NumWebVisitsMonth"))
# We select 6 since it can capture variables features very well
set.seed(20)
ica = fastICA(numerical.data, 6, fun = "logcosh", alpha = 1,
row.norm = T, maxit = 200,
tol = 0.0001, verbose = FALSE)
ica.loading = data.frame(t(ica$A)) %>%
rename_with(~ str_glue("IC{seq(.)}")) %>%
mutate(variable = names(numerical.data)) %>%
pivot_longer(cols = starts_with("IC"), names_to = "components", values_to = "loading")
# prepare data for heat map
colnames(ica.loading) = c("features","variable","value")
ica.loading$features = factor(ica.loading$features, levels = c("Education", "Marital_Status", "Kidhome", "Teenhome", "Age",
"Dt_Customer", "Income", "Recency", "MntWines", "MntFruits",
"MntMeatProducts", "MntFishProducts", "MntSweetProducts",
"MntGoldProds", "NumDealsPurchases", "NumWebPurchases",
"NumCatalogPurchases", "NumStorePurchases", "NumWebVisitsMonth"))
fa.plot = ggplot(fa.res.df, aes(x = variable, y = factor(features, level = features.order), fill = value)) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1, show.legend = FALSE) +
scale_fill_gradient2(low='blue',high='red') +
ylab("Features") + xlab("Factors") + ggtitle('FA') +
coord_fixed() + theme(plot.title = element_text(hjust = 0.5))
pr.plot = ggplot(pr.loading.df, aes(x = variable, y = factor(features, level = features.order), fill = value)) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1, show.legend = FALSE) +
scale_fill_gradient2(low='blue',high='red') + xlab("Components") + ggtitle('PCA') +
coord_fixed() + ylab(NULL) +
theme(axis.text.y=element_blank(), axis.ticks.y=element_blank(), plot.title = element_text(hjust = 0.5))
ica.plot = ggplot(ica.loading, aes(x = variable, y = factor(features, level = features.order), fill = value)) +
geom_tile(color = "white", lwd = 1.5, linetype = 1) +
scale_fill_gradient2(low='blue',high='red',limits=c(-1,1)) + xlab("Components") + ggtitle('ICA') +
coord_fixed() + ylab(NULL) +
theme(axis.text.y=element_blank(), axis.ticks.y=element_blank(), plot.title = element_text(hjust = 0.5))
# heat map comparison plot
grid.arrange(fa.plot, pr.plot, ica.plot, nrow = 1,
top=textGrob("Compare loadings among FA, PCA and ICA", gp=gpar(fontsize=15, font = 2)))
# elbow plot
fviz_nbclust(ica.latent, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2) + # add line for better visualisation
labs(subtitle = "Elbow method") # add subtitle
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
plot(ica.latent[,3],ica.latent[,4],col = kmean.model.4.cluster)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
plot(ica.latent[,2],ica.latent[,4],col = kmean.model.4.cluster)
library(arules)
library(arulesViz)
library(plyr)
groceries=read.csv("Groceries_dataset.csv")
### sort transactions by member number and transform to proper format
groceries.sorted = groceries[order(groceries$Member_number),]
groceries.sorted$Member_number = as.numeric(groceries.sorted$Member_number)
### transform the data from data frame to transactions
knitr::opts_chunk$set(echo = TRUE)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
scatterplot3d(ica.latent[,2],ica.latent[,],col = kmean.model.4.cluster)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
plot(ica.latent[,2],ica.latent[,],col = kmean.model.4.cluster)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(ica.latent[,c(1,2,3)],kmean.model.4.cluster)
??scatterplot3d
library(ggplot2)
library(reshape)
library(dplyr)
library(GGally)
library(corrplot)
library(lubridate)
library(forcats)
library(readr)
library(reshape)
library(polycor)
library(EFA.dimensions)
library(fastICA)
library(tidyr)
library(stringr)
library(grid)
library(gridExtra)
library(ica)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(ica.latent[,c(1,2,3)],kmean.model.4.cluster)
ica.latent[,c(1,2,3)]
library(ggplot2)
library(reshape)
library(dplyr)
library(GGally)
library(corrplot)
library(lubridate)
library(forcats)
library(readr)
library(reshape)
library(polycor)
library(EFA.dimensions)
library(fastICA)
library(tidyr)
library(stringr)
library(grid)
library(gridExtra)
library(ica)
library(scatterplot3d)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(ica.latent[,c(1,2,3)],kmean.model.4.cluster)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(ica.latent[,c(1,2,3)])
?scatterplot3d
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(scale(ica.latent[,c(1,2,3)]),color = kmean.model.4.cluster)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(min.max.scale(ica.latent[,1]),min.max.scale(ica.latent[,2]),min.max.scale(ica.latent[,3]),color = kmean.model.4.cluster)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(min.max.scale(ica.latent[,1]),min.max.scale(ica.latent[,2]),min.max.scale(ica.latent[,3]),color = kmean.model.4.cluster, main='Clusters in 3 dimensions',xlab ='Dimension 1',ylab= 'Dimension 2', zlab= 'Dimension 3')
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(min.max.scale(ica.latent[,1]),min.max.scale(ica.latent[,2]),min.max.scale(ica.latent[,3]),color = kmean.model.4.cluster, main='Clusters in 3 dimensions',xlab ='Dimension 1',ylab= 'Dimension 2', zlab= 'Dimension 3',scale.y = 1)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(min.max.scale(ica.latent[,1]),min.max.scale(ica.latent[,2]),min.max.scale(ica.latent[,3]),color = kmean.model.4.cluster, main='Clusters in 3 dimensions',xlab ='Dimension 1',ylab= 'Dimension 2', zlab= 'Dimension 3',scale.y = 2)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(min.max.scale(ica.latent[,1]),min.max.scale(ica.latent[,2]),min.max.scale(ica.latent[,3]),color = kmean.model.4.cluster, main='Clusters in 3 dimensions',xlab ='Dimension 1',ylab= 'Dimension 2', zlab= 'Dimension 3',scale.y = 1)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(min.max.scale(ica.latent[,1]),min.max.scale(ica.latent[,2]),min.max.scale(ica.latent[,3]),color = kmean.model.4.cluster, main='Clusters in 3 dimensions',xlab ='Dimension 1',ylab= 'Dimension 2', zlab= 'Dimension 3',scale.y = 1, pch = kmean.model.4.cluster)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(min.max.scale(ica.latent[,1]),min.max.scale(ica.latent[,2]),min.max.scale(ica.latent[,3]),color = kmean.model.4.cluster, main='Clusters in 3 dimensions',xlab ='Dimension 1',ylab= 'Dimension 2', zlab= 'Dimension 3',scale.y = 1)
kmean.model.4 = kmeans(ica.latent, 4, nstart = 10)
kmean.model.4.cluster = kmean.model.4$cluster
# Have a brief look at the cluster
# plot(ica.latent[,2],ica.latent[,1],col = kmean.model.4.cluster)
scatterplot3d(min.max.scale(ica.latent[,1]),min.max.scale(ica.latent[,2]),min.max.scale(ica.latent[,3]),color = kmean.model.4.cluster, main='Clusters in 3 dimensions',xlab ='Dimension 1',ylab= 'Dimension 2', zlab= 'Dimension 3',scale.y = 1)
rfm.R = data.clean$Recency
rfm.F = rowSums(data.clean[,16:20])
rfm.M = rowSums(data.clean[,10:15])
rfm.income = data.clean$Income
RFM = data.frame(rfm.R,rfm.F,rfm.M,rfm.income)
min.max.scale <- function(x){(x-min(x))/(max(x)-min(x))}
RFM$rfm.R.scaled = min.max.scale(RFM$rfm.R)
RFM$rfm.F.scaled = min.max.scale(RFM$rfm.F)
RFM$rfm.M.scaled = min.max.scale(RFM$rfm.M)
RFM$rfm.income.scaled = min.max.scale(RFM$rfm.income)
RFM$cluster = kmean.model.4.cluster
# Label the cluster
# plot the rfm in different clusters
RFM%>%
select(cluster, rfm.R.scaled, rfm.F.scaled, rfm.M.scaled,rfm.income.scaled)%>%
melt(id='cluster')%>%
ggplot(aes(as_factor(cluster), value))+
geom_boxplot()+
facet_wrap(~variable, ncol = 4)
# import data
data.ori = read.csv("customer-personality.csv")
# summary of data
str(data.ori)
# check for NA
sum(is.na(data.ori))
# check which columns contain NA
apply(is.na(data.ori), 2, which)
# remove NA rows
data.clean = data.ori[which(!is.na(data.ori$Income)),]
str(data.clean)
sum(is.na(data.clean))
# remove outliers from income and birth year
## income
data.clean <- data.clean[!(data.clean$Income >=200000),]
## birth year
data.clean <- data.clean[!(data.clean$Year_Birth <=1901),]
# converting 'Education', 'Marital status', and 'Dt_Customer' variables to categorical variables
## Education - Creating 3 categories
data.clean$Education[data.clean$Education == "Basic"] <- "1"
data.clean$Education[data.clean$Education == "Graduation"] <- "2"
data.clean$Education[data.clean$Education == "2n Cycle"] <- "3"
data.clean$Education[data.clean$Education == "Master"] <- "3"
data.clean$Education[data.clean$Education == "PhD"] <- "3"
data.clean$Education <- as.numeric(data.clean$Education)
## Marital Status - Creating 2 categories of Single and together
data.clean$Marital_Status[data.clean$Marital_Status == "Absurd"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "Alone"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "YOLO"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "Single"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "Together"] <- 1
data.clean$Marital_Status[data.clean$Marital_Status == "Married"] <- 1
data.clean$Marital_Status[data.clean$Marital_Status == "Divorced"] <- 0
data.clean$Marital_Status[data.clean$Marital_Status == "Widow"] <- 0
data.clean$Marital_Status <- as.numeric(data.clean$Marital_Status)
## Dt_customer
data.clean$Dt_Customer <- dmy(data.clean$Dt_Customer)
data.clean$Dt_Customer <- year(data.clean$Dt_Customer)
data.clean$Dt_Customer <- as.factor(data.clean$Dt_Customer)
data.clean$Dt_Customer <- fct_collapse(data.clean$Dt_Customer,
"3" = "2014",
"1" = "2012",
"2" = "2013")
data.clean$Dt_Customer <- as.numeric(levels(data.clean$Dt_Customer))[data.clean$Dt_Customer]
# Adding Age variable
data.clean$Age <- (2015 - data.clean$Year_Birth)
# filter numerical columns
numerical.data = data.clean[, c(3:21)]#:ncol(data.ori))]
str(numerical.data)
par(mfrow=c(1,1))
corr_simple <- function(data=numerical.data,sig=0.5){
#convert data to numeric in order to run correlations
#convert to factor first to keep the integrity of the data - each value will become a number rather than turn into NA
df_cor <- data %>% mutate_if(is.character, as.factor)
df_cor <- df_cor %>% mutate_if(is.factor, as.numeric)
#run a correlation and drop the insignificant ones
corr <- cor(df_cor)
#prepare to drop duplicates and correlations of 1
corr[lower.tri(corr,diag=TRUE)] <- NA
#drop perfect correlations
corr[corr == 1] <- NA
#turn into a 3-column table
corr <- as.data.frame(as.table(corr))
#remove the NA values from above
corr <- na.omit(corr)
#select significant values
corr <- subset(corr, abs(Freq) > sig)
#sort by highest correlation
corr <- corr[order(-abs(corr$Freq)),]
#print table
print(corr)
#turn corr back into matrix in order to plot with corrplot
mtx_corr <- reshape2::acast(corr, Var1~Var2, value.var="Freq")
#plot correlations visually
corrplot(mtx_corr, is.corr=T, tl.col="black", method = 'number', na.label=" ", number.cex=0.8 ,tl.cex=0.8)
}
corr_simple()
par(mfrow=c(4,5))
hist(data.clean$Education, main="Education", xlab=" ")
hist(data.clean$Marital_Status, main="Marital_Status", xlab=" ", ylab = " ")
hist(data.clean$Income, main="Income", xlab=" ", ylab = " ")
hist(data.clean$Kidhome, main="Kidhome", xlab=" ", ylab = " ")
hist(data.clean$Teenhome, main="Teenhome", xlab=" ", ylab = " ")
hist(data.clean$Dt_Customer, main="Dt_Customer", xlab=" ")
hist(data.clean$Recency, main="Recency", xlab=" ", ylab = " ")
hist(data.clean$MntWines, main="MntWines", xlab=" ", ylab = " ")
hist(data.clean$MntFruits, main="MntFruits", xlab=" ", ylab = " ")
hist(data.clean$MntMeatProducts, main="MntMeat", xlab=" ", ylab = " ")
hist(data.clean$MntFishProducts, main="MntFish", xlab=" ")
hist(data.clean$MntSweetProducts, main="MntSweet", xlab=" ", ylab = " ")
hist(data.clean$MntGoldProds, main="MntGold", xlab=" ", ylab = " ")
hist(data.clean$NumDealsPurchases, main="NumDeals", xlab=" ", ylab = " ")
hist(data.clean$NumWebPurchases, main="NumWeb", xlab=" ", ylab = " ")
hist(data.clean$NumCatalogPurchases, main="NumCatalog", xlab=" ")
hist(data.clean$NumStorePurchases, main="NumStore", xlab=" ", ylab = " ")
hist(data.clean$NumWebVisitsMonth, main="NumWebVisits", xlab=" ", ylab = " ")
hist(data.clean$Age, main="Age", xlab=" ", ylab = " ")
par(mfrow=c(1,1))
features.order = c("Education", "Marital_Status", "Kidhome", "Teenhome", "Age",
"Dt_Customer", "Income", "Recency", "MntWines", "MntFruits",
"MntMeatProducts", "MntFishProducts", "MntSweetProducts",
"MntGoldProds", "NumDealsPurchases", "NumWebPurchases",
"NumCatalogPurchases", "NumStorePurchases", "NumWebVisitsMonth")
# get the polychroic correlation
fa.cor = POLYCHORIC_R(numerical.data)
# look at eigenvector of the correlation to see how many factors we use
fa.eigen = eigen(fa.cor)
fa.eigen$values
# in decreasing values
# higher = more important
# rule of thumb to see the number of variables we should use? Do the sum
sum(fa.eigen$values)
# to select number of factors
cumsum(fa.eigen$values) / ncol(numerical.data) # Which is 19 here
# seeing this, using the first 4, we can explain 79% of the data
# draw screen plot for better visualisation
# use the scree plot
plot(fa.eigen$values, type = "b", ylab = "Eigenvalues", xlab = "Factor") # we choose 4 factors
# factor analysis with rotation
fa = factanal(x = numerical.data, factors = 4, rotation = "promax", scores = "Bartlett")
head(fa$scores)
# show the result
summary(lm(Factor2 ~ Factor1, data = as.data.frame(fa$scores)))
fa.loading  = data.frame(fa$loadings[1:19,1:4])
fa.loading$features = rownames(fa.loading)
colnames(fa.loading) = c('F1','F2','F3','F4','features')
# factor analysis with rotation
fa = factanal(x = numerical.data, factors = 4, rotation = "promax", scores = "Bartlett")
head(fa$scores)
# show the result
summary(lm(Factor2 ~ Factor1, data = as.data.frame(fa$scores)))
fa.loading  = data.frame(fa$loadings[1:19,1:4])
fa.loading$features = rownames(fa.loading)
colnames(fa.loading) = c('F1','F2','F3','F4','features')
# create a new data frame with the selected principal components
# prepare data for heat map
fa.df = melt(fa.loading)
fa.df$features = factor(fa.df$features, levels = c("Education", "Marital_Status", "Kidhome", "Teenhome", "Age",
"Dt_Customer", "Income", "Recency", "MntWines", "MntFruits",
"MntMeatProducts", "MntFishProducts", "MntSweetProducts",
"MntGoldProds", "NumDealsPurchases", "NumWebPurchases",
"NumCatalogPurchases", "NumStorePurchases", "NumWebVisitsMonth"))
# Apply PCA to data
pc.res = prcomp(numerical.data, scale = TRUE)
pc.res
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE,fig.width=6, fig.height=6,warning=FALSE)
# create a new data frame with the selected principal components
# prepare data for heat map
fa.df = melt(fa.loading)
fa.df$features = factor(fa.df$features, levels = c("Education", "Marital_Status", "Kidhome", "Teenhome", "Age",
"Dt_Customer", "Income", "Recency", "MntWines", "MntFruits",
"MntMeatProducts", "MntFishProducts", "MntSweetProducts",
"MntGoldProds", "NumDealsPurchases", "NumWebPurchases",
"NumCatalogPurchases", "NumStorePurchases", "NumWebVisitsMonth"))
# create a new data frame with the selected principal components
# prepare data for heat map
fa.df = melt(fa.loading)
fa.df$features = factor(fa.df$features, levels = c("Education", "Marital_Status", "Kidhome", "Teenhome", "Age", "Dt_Customer", "Income", "Recency", "MntWines", "MntFruits", "MntMeatProducts", "MntFishProducts", "MntSweetProducts","MntGoldProds", "NumDealsPurchases", "NumWebPurchases", "NumCatalogPurchases", "NumStorePurchases", "NumWebVisitsMonth"))
?fviz_nbclust
??fviz_nbclust
rfm.R = data.clean$Recency
rfm.F = rowSums(data.clean[,16:20])
rfm.M = rowSums(data.clean[,10:15])
rfm.income = data.clean$Income
RFM = data.frame(rfm.R,rfm.F,rfm.M,rfm.income)
RFM$rfm.R.scaled = min.max.scale(RFM$rfm.R)
RFM$rfm.F.scaled = min.max.scale(RFM$rfm.F)
RFM$rfm.M.scaled = min.max.scale(RFM$rfm.M)
RFM$rfm.income.scaled = min.max.scale(RFM$rfm.income)
RFM$cluster = kmean.model.4.cluster
# Label the cluster
# plot the rfm in different clusters
# plot the rfm in different clusters
RFM%>%
select(cluster, rfm.R.scaled, rfm.F.scaled, rfm.M.scaled,rfm.income.scaled)%>%
melt(id='cluster')%>%
ggplot(aes(as_factor(cluster), value, fill=as.factor(cluster)))+
scale_fill_manual('Cluster',values=c("#ff8c7a", "#92C5DE", "yellow", "#B8E186"))+
geom_boxplot()+
facet_wrap(~variable, ncol = 4)+
labs(x = "Cluster", labs="Cluster")
# plot the features vs different clusters
data.scaled <- data.clean
data.scaled <- data.frame(sapply(data.scaled, min.max.scale))
data.scaled$cluster <- RFM$cluster
data.scaled%>%
select(cluster, Age, Kidhome, Teenhome,Education, Marital_Status,
MntWines, MntFruits, MntMeatProducts, MntFishProducts,
MntSweetProducts, MntGoldProds, NumDealsPurchases, NumWebPurchases,
NumCatalogPurchases, NumStorePurchases, NumWebVisitsMonth)%>%
melt(id='cluster')%>%
ggplot(aes(as_factor(cluster), value, fill=as.factor(cluster)))+
scale_fill_manual(values=c("#ff8c7a", "#92C5DE", "yellow", "#B8E186"))+
geom_boxplot()+
facet_wrap(~variable, ncol = 4) +
theme_light() +
labs(x = "Cluster", fill = "Cluster") +
scale_color_manual(name="Cluster",values=c("1","2","3","4"))
